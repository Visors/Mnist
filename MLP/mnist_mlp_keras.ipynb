{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mnist MLP",
   "id": "a054e699655ba5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Modules",
   "id": "912b6a187a1f1e64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:42.397764Z",
     "start_time": "2025-02-17T04:18:42.390325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from PIL import Image"
   ],
   "id": "dbd52efbe103d40d",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Data\n",
    "\n",
    "Load the MNIST dataset using the Keras API. Visualize some of the data."
   ],
   "id": "c5bab92b319b3156"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:42.708852Z",
     "start_time": "2025-02-17T04:18:42.422807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "id": "4b2b1a3becaadb74",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:43.182756Z",
     "start_time": "2025-02-17T04:18:42.747549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize some of the data\n",
    "def plot_images(images, labels, title):\n",
    "    plt.figure(figsize=(13, 2))  # Size of the plot\n",
    "    plt.suptitle(title)  # Set the title of the plot\n",
    "    for i in range(10):  # Plot the first 10 images\n",
    "        plt.subplot(1, 10, i + 1)  # Create a subplot with 1 row and 10 columns and select the i+1-th position\n",
    "        plt.imshow(images[i], cmap='gray')  # Show the i-th image in the plot and set the colormap to gray\n",
    "        plt.title(labels[i])  # Set the title of the i-th subplot to the label of the i-th image\n",
    "        plt.axis('off')  # Disable the axis of the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_images(x_train, y_train[:10], \"Training Images\")"
   ],
   "id": "ff1cbb4a6f4a9b53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1300x200 with 10 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocess Data\n",
    "\n",
    "The MNIST dataset consists of `70,000` `28x28` black-and-white images of handwritten digits extracted from two NIST databases. There are `60,000` images in the training dataset and `10,000` images in the validation dataset, one class per digit so a total of `10` classes, with `7,000` images (`6,000` train images and `1,000` test images) per class. Half of the image were drawn by Census Bureau employees and the other half by high school students (this split is evenly distributed in the training and testing sets)."
   ],
   "id": "5fec8a45d6d25c46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Flatten Before Normalize\n",
    "\n",
    "MLP requires the features to be a **1D-vector**. To fit this requirement, the `28*28` images need to be flattened into a **1D-vector** and normalized to a value between `0` and `1`. The labels also need to be converted into a `1x10` array where each row is a one-hot vector."
   ],
   "id": "ac8b2a457c835e7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:43.387968Z",
     "start_time": "2025-02-17T04:18:43.257664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Flatten the data and normalize\n",
    "x_train = x_train.astype('float32').reshape(-1,\n",
    "                                            784) / 255.0  # Flatten the images to 1x784 arrays, -1 means that the size of that dimension is determined by the other dimensions and the provided value.\n",
    "x_test = x_test.astype('float32').reshape(-1, 784) / 255.0"
   ],
   "id": "163708651756de71",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:43.450853Z",
     "start_time": "2025-02-17T04:18:43.437171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert labels to one-hot vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)  # Convert the labels to one-hot vectors\n",
    "y_test = tf.keras.utils.to_categorical(y_test,\n",
    "                                       10)  # One-hot encode means that each label is represented as a vector of length 10 where the index of the 1 is the value of the digit. For example, the label `5` would be `[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]`."
   ],
   "id": "49cb7ff3624f2855",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:43.540783Z",
     "start_time": "2025-02-17T04:18:43.531999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(y_train[:10])\n",
    "print(y_test[:10])"
   ],
   "id": "3032ef4ce59deca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create the Model",
   "id": "5a4150f90599306c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:43.689878Z",
     "start_time": "2025-02-17T04:18:43.648442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential({\n",
    "    Dense(256, activation='relu', input_shape=(784,)),  # Create a model with 128 neurons in the first hidden layer\n",
    "    Dense(256, activation='relu'),  # Create a model with 128 neurons in the second hidden layer\n",
    "    Dense(10, activation='softmax')  # Create a model with 10 neurons in the output layer\n",
    "})"
   ],
   "id": "35943c485850fac2",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compile the Model",
   "id": "64d2b481fe9bebca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:43.859852Z",
     "start_time": "2025-02-17T04:18:43.838312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\n",
    "    'accuracy'])  # Compile the model with the Adam optimizer, the categorical crossentropy loss function, and the accuracy metric"
   ],
   "id": "2de77231ae719da7",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the Model",
   "id": "f7c2a54423ae9dd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:18:44.269781Z",
     "start_time": "2025-02-17T04:18:43.918608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=128,\n",
    "          validation_split=0.2)  # Train the model with 10 epochs, a batch size of 32, and a validation split of 20%. Validation split means that 20% of the training data will be used as validation data."
   ],
   "id": "9a94a83310d4e200",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(128, 10), output.shape=(128, 256)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[124], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Train the model with 10 epochs, a batch size of 32, and a validation split of 20%. Validation split means that 20% of the training data will be used as validation data.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py:587\u001B[0m, in \u001B[0;36mcategorical_crossentropy\u001B[0;34m(target, output, from_logits, axis)\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m e1, e2 \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(target\u001B[38;5;241m.\u001B[39mshape, output\u001B[38;5;241m.\u001B[39mshape):\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e1 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m e2 \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m e1 \u001B[38;5;241m!=\u001B[39m e2:\n\u001B[0;32m--> 587\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    588\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArguments `target` and `output` must have the same shape. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    589\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    590\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, output.shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    591\u001B[0m         )\n\u001B[1;32m    593\u001B[0m output, from_logits \u001B[38;5;241m=\u001B[39m _get_logits(\n\u001B[1;32m    594\u001B[0m     output, from_logits, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSoftmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    595\u001B[0m )\n\u001B[1;32m    596\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m from_logits:\n",
      "\u001B[0;31mValueError\u001B[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(128, 10), output.shape=(128, 256)"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Save the Model",
   "id": "7e105403ec6a037e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save(\"models/mnist_mlp.keras\")  # Save the model to a file",
   "id": "51f6a41c94f76741",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the Model",
   "id": "9f1e8df193214176"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss: \", test_loss)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ],
   "id": "d2f723f9ccc8d80b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Make Predictions",
   "id": "5468a24fdabb8f0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def predict_handwriting(model_path, image_folder):\n",
    "    # 加载训练好的模型\n",
    "    saved_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # 获取所有图片路径\n",
    "    image_paths = glob.glob(os.path.join(image_folder, \"*.png\")) + \\\n",
    "                  glob.glob(os.path.join(image_folder, \"*.jpg\")) + \\\n",
    "                  glob.glob(os.path.join(image_folder, \"*.jpeg\"))\n",
    "\n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {image_folder}\")\n",
    "        return\n",
    "\n",
    "    # 创建可视化布局（每行最多5张）\n",
    "    num_images = len(image_paths)\n",
    "    cols = 5\n",
    "    rows = int(np.ceil(num_images / cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, rows * 3))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)  # 处理单行情况\n",
    "\n",
    "    # 设置全局标题\n",
    "    fig.suptitle(\"Handwriting Digit Recognition Results\", fontsize=16, y=1.02)\n",
    "\n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        try:\n",
    "            # 预处理图像（匹配MNIST格式）\n",
    "            img = Image.open(img_path).convert('L')  # 转为灰度\n",
    "            img = img.resize((28, 28))  # 调整尺寸\n",
    "            img_array = np.array(img)  # 转为numpy数组\n",
    "\n",
    "            # 标准化处理（反转颜色 + 归一化）\n",
    "            img_array = (255 - img_array) / 255.0  # 假设输入是黑底白字\n",
    "            # img_array = img_array / 255.0  # 假设输入是白底黑字\n",
    "\n",
    "            # 适配MLP模型输入形状 (1, 784)\n",
    "            input_data = img_array.astype(\"float32\").reshape(1, 784)\n",
    "\n",
    "            # 进行预测\n",
    "            predictions = saved_model.predict(input_data, verbose=0)\n",
    "            pred_class = np.argmax(predictions)\n",
    "            confidence = np.max(predictions)\n",
    "\n",
    "            # 绘制结果\n",
    "            ax = axes[idx // cols, idx % cols]\n",
    "            ax.imshow(img, cmap='gray')  # 显示原始尺寸图像\n",
    "            ax.set_title(f\"Pred: {pred_class}\\nProb: {confidence:.2f}\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {os.path.basename(img_path)}: {str(e)}\")\n",
    "\n",
    "    # 隐藏空白子图\n",
    "    for j in range(len(image_paths), rows * cols):\n",
    "        axes[j // cols, j % cols].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "af69b653214c47da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 使用示例\n",
    "predict_handwriting(\n",
    "    model_path=\"models/mnist_mlp.keras\",\n",
    "    image_folder=\"images/handwriting\"\n",
    ")"
   ],
   "id": "139c905209c1e53c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
